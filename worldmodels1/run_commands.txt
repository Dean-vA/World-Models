#vae_train.py - multi-gpu training
CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.run --nproc_per_node 4 src/worldmodels1/train_vae.py --data_path collected_data.npy --num_workers 50 --epochs 50

#create_latent_data.py - single gpu
CUDA_VISIBLE_DEVICES=0 python create_latent_data.py --data_path ./../../collected_data.npy --batch_size 64 --num_workers 8 --vae_path ./../../vae.pth
